---
layout: review
title:  Multisource and Multitemporal Data Fusion in Remote Sensing
tags:   deep-learning segmentation remote-sensing CNN hyperspectral multi-task-learning point-cloud
cite:
    authors: "Pedram Ghamisi, et al."
    title:   "Multisource and Multitemporal Data Fusion in Remote Sensing"
    venue:   "arXiv preprint arXiv:1812.08287. 2018 Dec 19."
pdf:  https://arxiv.org/pdf/1812.08287.pdf
---

**KEYSWORDS: light detection and ranging (LiDAR), terrestrial laser scanning (TLS), synthetic aperture radar (SAR), Gravity Recovery And Climate Experiment (GRACE), Medium Resolution Imaging Spectrometer (MERIS), electromagnetic spectrum (EMS)**

## Introduction

A recents increase in remote sensing and ancillary datasets, opens up the possibility of utilizing multimodal datasets in a joint manner to further improve the performance of the processing approaches with respect to the application at hand.
The integration of the temporal information with the spatial and/or spectral/backscattering information of the remotely sensed data is possible and helps to move from a representation of 2D/3D data to 4D data structures, where the time variable adds new information as well as challenges for the information extraction algorithms.

This paper brings together the advances of multisource and multitemporal data fusion approaches with different research communities and provides a thorough and discipline-specific starting point for researchers at different levels.
More specifically, it provides an overview of many important contributions dedicated to the topics of pansharpening and resolution enhancement, point cloud data fusion, hyperspectral and LiDAR data fusion, multitemporal data fusion, as well as big data and social media.

The remote sensors onboard the above platforms may vary in multiple dimensions (e.g. types of properties sensed, spatial and spectral resolutions of the data, etc.).

![](/article/images/mmdfrs/fig1.jpg)

## Spatio-spectral fusion
*  Component Substitution
* Multiresolution Analysis
* Geostatistical Analysis
* Subspace Representation
* Sparse Representation

## Spatio-temporal fusion
* The spatial and temporal adaptive reflectance fusion model(STARFM).
* For heterogeneous landscapes, an enhanced STARFM (ESTARFM).

![](/article/images/mmdfrs/fig2.jpg)

## Point Cloud
* Point cloud level: Enrich the initial point cloud P with new point features.
* Image/Voxel level: Derive new image layers representing 3D point cloud information.
* Feature level: Fusion of point cloud information on the segment/object level.

![](/article/images/mmdfrs/fig6.jpg)

## Hyperspectral and LiDAR

![](/article/images/mmdfrs/fig78.jpg)

## Deep Learning

![](/article/images/mmdfrs/fig10.jpg)

## Fusion

![](/article/images/mmdfrs/fig14.jpg)

![](/article/images/mmdfrs/table3.jpg)

## Conclusion

The field of multisensor and multitemporal data fusion for remotely sensed imagery is enormous.
This article focuses on advances in multisource and multitemporal data fusion approaches with respect to different research communities.
As they demonstrated through the challenges and possible future research of each section, although the field of remote sensing data fusion is mature, there are still doors left open for investigation.

